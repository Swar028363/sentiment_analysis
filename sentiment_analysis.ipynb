{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cbaff0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e6bec-164e-474d-9ae7-6f244d8e54ae",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e96d8f-2c77-443b-896c-a00a3803ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "import string\n",
    "import contractions\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from autocorrect import Speller\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, opinion_lexicon\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d192de1-8706-4325-b81f-5a75cc3aabbe",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "Dataset: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11399cc6-1da6-4c00-8288-77a1c2c657ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/IMDB_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f184e2-6c38-4029-8d63-545a12e560c9",
   "metadata": {},
   "source": [
    "## Removing for null and Deuplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b951ce5d-ce2f-49e1-b10b-a0a31ef7d0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b217eae-f037-478d-8ae5-0e25e4f33906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e634e9-7671-4841-ab17-b12632be8451",
   "metadata": {},
   "source": [
    "## Lable Encoding target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b2a00e-140d-4d3e-ae66-97fc75533dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    24884\n",
       "negative    24698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f81d3e4-b14b-4c7b-b241-b1c11929f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\KMSpico\\temp\\ipykernel_9232\\1907568225.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_LE'] = df['sentiment'].map(lable_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_LE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "       sentiment_LE  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "49995             1  \n",
       "49996             0  \n",
       "49997             0  \n",
       "49998             0  \n",
       "49999             0  \n",
       "\n",
       "[49582 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LE = lable encoded\n",
    "lable_map = {\n",
    "    'positive' : 1,\n",
    "    'negative' : 0\n",
    "}\n",
    "df['sentiment_LE'] = df['sentiment'].map(lable_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d817978-f8e7-4583-9826-4b50696ef0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_LE\n",
       "1    24884\n",
       "0    24698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_LE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436a9d0-763c-41e5-ac3a-29eb0621e750",
   "metadata": {},
   "source": [
    "## Removig\n",
    "1. HTML Tags\n",
    "2. Expand contractions\n",
    "3. Emoji handling\n",
    "4. Spelling correction\n",
    "5. Lowercase + remove extra spaces\n",
    "6. Tokenization + lemmatization\n",
    "7. Negation handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e72004-61a5-4f47-9b65-225452dcc41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "df['review'][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5373355-6335-4d3b-a361-37a4a3a8f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'enraged_face', 'absolutely', 'amazing', 'actor', 'dissapointng']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy (disable unnecessary pipeline components for speed)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "spell = Speller()\n",
    "\n",
    "# Default custom stopwords\n",
    "custom_stop_words = {\n",
    "    \"movie\", \"film\"\n",
    "}\n",
    "\n",
    "# Default negations\n",
    "negations = {\n",
    "    \"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\",\n",
    "    \"didnt\", \"doesnt\", \"ain't\", \"aren't\", \"can't\", \"couldn't\",\n",
    "    \"daren't\", \"didn't\", \"doesn't\", \"dont\", \"hadnt\", \"hasnt\",\n",
    "    \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\", \"don't\", \n",
    "    \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\", \n",
    "    \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\",\n",
    "    \"nothing\", \"nowhere\", \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\",\n",
    "    \"wasnt\", \"werent\", \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\",\n",
    "    \"wasn't\", \"weren't\", \"without\", \"wont\", \"wouldnt\", \"won't\",\n",
    "    \"wouldn't\", \"rarely\", \"seldom\", \"despite\"\n",
    "}\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def handle_emoji(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "def correct_spelling_fast(text):\n",
    "    return \" \".join([str(spell(w) or w) for w in text.split()])\n",
    "\n",
    "def tokenize(text, lemmatize=True, remove_stopwords=True, remove_punc=True,\n",
    "             custom_stop_words=None, remove_custom_stop_words=True):\n",
    "    if custom_stop_words is None:\n",
    "        custom_stop_words = set()\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        tok = token.text\n",
    "        if lemmatize:\n",
    "            tok = token.lemma_.lower()\n",
    "        else:\n",
    "            tok = tok.lower()\n",
    "        if remove_punc and token.is_punct:\n",
    "            continue\n",
    "        if remove_stopwords and token.is_stop:\n",
    "            continue\n",
    "        if remove_custom_stop_words and tok in custom_stop_words:\n",
    "            continue\n",
    "        tokens.append(tok)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def handle_negations(tokens, combine=True):\n",
    "    \"\"\"\n",
    "    If combine=True, combines negation with next token: 'not good' -> 'not_good'\n",
    "    If combine=False, keeps tokens separate: ['not', 'good']\n",
    "    \"\"\"\n",
    "    if not combine:\n",
    "        return tokens\n",
    "    \n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        tok = tokens[i]\n",
    "        if tok in negations and i < len(tokens) - 1:\n",
    "            result.append(tok + \"_\" + tokens[i+1])\n",
    "            i += 2\n",
    "        else:\n",
    "            result.append(tok)\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "# Main customizable preprocessing function\n",
    "\n",
    "def preprocess_text(\n",
    "    text,\n",
    "    remove_html=True,\n",
    "    expand_contr=True,\n",
    "    handle_emoji_flag=True,\n",
    "    spelling_correction=False,\n",
    "    lowercase=True,\n",
    "    lemmatize=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_punc=True,\n",
    "    custom_stop_words=None,\n",
    "    remove_custom_stop_words=True,\n",
    "    negation_combine=True\n",
    "):\n",
    "    # 1. HTML\n",
    "    if remove_html:\n",
    "        text = clean_html(text)\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    if expand_contr:\n",
    "        text = expand_contractions(text)\n",
    "    \n",
    "    # 3. Emoji handling\n",
    "    if handle_emoji_flag:\n",
    "        text = handle_emoji(text)\n",
    "    \n",
    "    # 4. Spelling correction\n",
    "    if spelling_correction:\n",
    "        text = correct_spelling_fast(text)\n",
    "    \n",
    "    # 5. Lowercase + remove extra spaces\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 6. Tokenization + lemmatization\n",
    "    tokens = tokenize(text, lemmatize=lemmatize, remove_stopwords=remove_stopwords,\n",
    "                      remove_punc=remove_punc, custom_stop_words=custom_stop_words, remove_custom_stop_words=remove_custom_stop_words)\n",
    "    \n",
    "    # 7. Negation handling\n",
    "    tokens = handle_negations(tokens, combine=negation_combine)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "sample_text = \"<p>I didn't like this movie at all! ðŸ˜¡!!! The moovie was abolutly amaziing but the actrs were dissapointng.</p>\"\n",
    "\n",
    "tokens = preprocess_text(\n",
    "    sample_text,\n",
    "    remove_html=True,\n",
    "    expand_contr=True,\n",
    "    handle_emoji_flag=True,\n",
    "    spelling_correction=True,\n",
    "    lowercase=True,\n",
    "    lemmatize=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_punc=True,\n",
    "    custom_stop_words=custom_stop_words,\n",
    "    remove_custom_stop_words=True,\n",
    "    negation_combine=True\n",
    ")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa1fb79-6134-4190-9eb5-f6adaeb46054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 39.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['think',\n",
       " 'wonderful',\n",
       " 'way',\n",
       " 'spend',\n",
       " 'time',\n",
       " 'hot',\n",
       " 'summer',\n",
       " 'weekend',\n",
       " 'sit',\n",
       " 'air',\n",
       " 'condition',\n",
       " 'theater',\n",
       " 'watch',\n",
       " 'light',\n",
       " 'hearted',\n",
       " 'comedy',\n",
       " 'plot',\n",
       " 'simplistic',\n",
       " 'dialogue',\n",
       " 'witty',\n",
       " 'character',\n",
       " 'likable',\n",
       " 'bread',\n",
       " 'suspect',\n",
       " 'serial',\n",
       " 'killer',\n",
       " 'disappoint',\n",
       " 'realize',\n",
       " 'match',\n",
       " 'point',\n",
       " '2',\n",
       " 'risk',\n",
       " 'addiction',\n",
       " 'think',\n",
       " 'proof',\n",
       " 'woody',\n",
       " 'allen',\n",
       " 'fully',\n",
       " 'control',\n",
       " 'style',\n",
       " 'grow',\n",
       " 'love.this',\n",
       " 'laugh',\n",
       " 'woody',\n",
       " 'comedy',\n",
       " 'year',\n",
       " 'dare',\n",
       " 'decade',\n",
       " 'impress',\n",
       " 'scarlet',\n",
       " 'johanson',\n",
       " 'manage',\n",
       " 'tone',\n",
       " 'sexy',\n",
       " 'image',\n",
       " 'jump',\n",
       " 'right',\n",
       " 'average',\n",
       " 'spirited',\n",
       " 'young',\n",
       " 'woman.this',\n",
       " 'crown',\n",
       " 'jewel',\n",
       " 'career',\n",
       " 'witty',\n",
       " 'devil',\n",
       " 'wear',\n",
       " 'prada',\n",
       " 'interesting',\n",
       " 'superman',\n",
       " 'great',\n",
       " 'comedy',\n",
       " 'friend']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_text(\n",
    "    df['review'][n],\n",
    "    remove_html=True,\n",
    "    expand_contr=False,\n",
    "    handle_emoji_flag=True,\n",
    "    spelling_correction=False,\n",
    "    lowercase=True,\n",
    "    lemmatize=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_punc=True,\n",
    "    custom_stop_words=custom_stop_words,\n",
    "    remove_custom_stop_words=True,\n",
    "    negation_combine=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5237b7-7d2d-4819-932f-55a5526fe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_review'] = df['review'].apply(lambda review: \" \".join(preprocess_text(\n",
    "    review,\n",
    "    remove_html=True,\n",
    "    expand_contr=False,\n",
    "    handle_emoji_flag=True,\n",
    "    spelling_correction=False,\n",
    "    lowercase=True,\n",
    "    lemmatize=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_punc=True,\n",
    "    custom_stop_words=custom_stop_words,\n",
    "    remove_custom_stop_words=True,\n",
    "    negation_combine=False\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8247cbf-e5cb-49ff-ab16-dfe8b349bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_review'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f7a29-df86-4d74-9f7c-06adc3f5f2c6",
   "metadata": {},
   "source": [
    "# Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dfb0d1-cf76-4aaf-81ab-0839c3b21e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_text = ' '.join(df['review'].astype(str))\n",
    "all_cleaned_text = ' '.join(df['processed_review'].astype(str))\n",
    "\n",
    "all_pos_raw_text = ' '.join(df.loc[df['sentiment_LE'] == 1, 'review'].astype(str))\n",
    "all_neg_raw_text = ' '.join(df.loc[df['sentiment_LE'] == 0, 'review'].astype(str))\n",
    "\n",
    "all_pos_cleaned_text = ' '.join(df.loc[df['sentiment_LE'] == 1, 'processed_review'].astype(str))\n",
    "all_neg_cleaned_text = ' '.join(df.loc[df['sentiment_LE'] == 0, 'processed_review'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897acc1c-58ae-4dcf-922b-7101eadabf68",
   "metadata": {},
   "source": [
    "### Raw reviwes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91650a40-397c-4251-bb97-4d6ff2531155",
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color='black',\n",
    "    max_words=200\n",
    ").generate(all_raw_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10241f-55ae-41fb-bf94-86dd5e699da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bd986-3c15-4720-81dc-da6627a82588",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_pos_raw_text text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color='black',\n",
    "    max_words=200\n",
    ").generate(all_pos_raw_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c018dd-0c9d-411d-886f-c54baf9220dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_pos_raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37213b1d-1b2a-4a08-bb16-93f48c3d6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_neg_raw_text text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color='black',\n",
    "    max_words=200\n",
    ").generate(all_neg_raw_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c682ab1-57da-430c-ae96-a86e61b70e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_neg_raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da7c96-3953-4cc0-8c17-e928de3ffcaa",
   "metadata": {},
   "source": [
    "### Preped reviwes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92d2ca-7d61-4de6-8da8-6d5678275fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaned text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color=\"black\",\n",
    "    max_words=200\n",
    ").generate(all_cleaned_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d1336-5b3a-47dd-b92c-cf8f1ee1fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6508135-ddb3-418b-ba05-6a5026514103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_pos_cleaned_text text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color='black',\n",
    "    max_words=200\n",
    ").generate(all_pos_cleaned_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c6c2b-cbc1-48f4-a589-759029fbeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_pos_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea686b5-623a-499f-a3c3-34e939de7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_neg_cleaned_text text\n",
    "wordcloud = WordCloud(\n",
    "    width=1000, height=500,\n",
    "    background_color='black',\n",
    "    max_words=200\n",
    ").generate(all_neg_cleaned_text)\n",
    "\n",
    "plt.figure(figsize=(12,6), facecolor='black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3cd5a-45d1-451e-b3c1-09b8ced0afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_neg_cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b5738-bb44-4d8a-af18-c604c8edac70",
   "metadata": {},
   "source": [
    "## Countig number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58238404-ff5b-4e6a-a803-d56b0eb79626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_review_word_len'] = df['processed_review'].apply(lambda x: len(x.split()))\n",
    "df['processed_review_word_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94819a7c-4bc6-419a-a87e-bc25e2931287",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['processed_review_word_len'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0211d-b87c-4189-b3af-c51b6618b79b",
   "metadata": {},
   "source": [
    "## counting positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade598a-54c6-4c01-bac1-40d0c3c53b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "def count_positive_words(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    pos_count = 0\n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "        if word in positive_words:\n",
    "            pos_count += 1\n",
    "    return pos_count\n",
    "\n",
    "def count_negative_words(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    neg_count = 0\n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "        if word in negative_words:\n",
    "            neg_count += 1\n",
    "    return neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03261d16-b5f7-4159-817b-4ad521f9e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "df['processed_review'][n], df['sentiment'][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e46d6c-3761-47cb-818b-0d4d449599e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = count_positive_words(df['processed_review'][n])\n",
    "neg = count_negative_words(df['processed_review'][n])\n",
    "pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a0ee7-549f-4e26-a60d-48d674f03d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts = df['processed_review'].apply(count_positive_words)\n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238ecfc-112a-4719-ad8b-5bdda223f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_counts = df['processed_review'].apply(count_negative_words)\n",
    "neg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886a28e-6bba-48ed-8896-ac6f2b1a8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratio = pos_counts / neg_counts\n",
    "pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc03dd-1f4e-4bf7-a202-bf3612d70b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_neg_ratio'] = pos_neg_ratio\n",
    "del pos_neg_ratio\n",
    "df['pos_counts'] = pos_counts\n",
    "del pos_counts\n",
    "df['neg_counts'] = neg_counts\n",
    "del neg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cd625-bd89-47a4-8441-8dc557df5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sentiment', 'pos_neg_ratio', 'pos_counts', 'neg_counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d0f09-2686-4f3d-a8d2-4a85542972f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(numeric_only=True), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526d1cc-32a9-42b7-9a3e-2bc059486c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/preped/preped_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee2b2a-7b8a-4b55-a81e-3f7e67318ed9",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40fd32-99c0-4353-9390-d358f39de46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(\n",
    "    max_features=20000, \n",
    "    min_df=10,\n",
    "    ngram_range=(1,3),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "tfid_vecs = tfid.fit_transform(df['processed_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4940399-becd-43aa-b846-686eb8c4750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vecs.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372902d-0490-4037-85f7-d3e222f8f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92f133-8982-480b-af30-4077d0138539",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df = pd.DataFrame(tfid_vecs.toarray(), columns=tfid.get_feature_names_out())\n",
    "tfid_df['sentiment_LE'] = df['sentiment_LE']\n",
    "tfid_df['pos_neg_ratio'] = df['pos_neg_ratio']\n",
    "tfid_df['pos_counts'] = df['pos_counts']\n",
    "tfid_df['neg_counts'] = df['neg_counts']\n",
    "tfid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622b38c-3f26-4eed-a0ca-ef283f25262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df.to_csv('dataset/preped/tfid_df_max_feature=20000_min_df=10_ngram_range=(1,3)_sublinear_tf=True.csv', dtype='float32', index=False)\n",
    "del tfid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4b8d0-3258-4427-adff-f9d89f7e0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfid, tfid_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c5225-04ce-4695-aff0-38d575fbe117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows per chunk\n",
    "chunksize = 10000\n",
    "n = 20  \n",
    "\n",
    "# accumulators\n",
    "pos_sum = None\n",
    "neg_sum = None\n",
    "\n",
    "use_cols = None  # to fix column order after first chunk\n",
    "\n",
    "for chunk in pd.read_csv('dataset/preped/tfid_df.csv', dtype='float32', chunksize=chunksize):\n",
    "    if use_cols is None:\n",
    "        use_cols = [c for c in chunk.columns if c not in ['sentiment_LE', 'pos_neg_ratio', 'pos_counts', 'neg_counts']]\n",
    "        pos_sum = pd.Series(0, index=use_cols, dtype='float32')\n",
    "        neg_sum = pd.Series(0, index=use_cols, dtype='float32')\n",
    "\n",
    "    # positive rows\n",
    "    pos_rows = chunk[chunk['sentiment_LE'] == 1][use_cols]\n",
    "    pos_sum = pos_sum.add(pos_rows.sum(axis=0), fill_value=0)\n",
    "\n",
    "    # negative rows\n",
    "    neg_rows = chunk[chunk['sentiment_LE'] == 0][use_cols]\n",
    "    neg_sum = neg_sum.add(neg_rows.sum(axis=0), fill_value=0)\n",
    "\n",
    "# take top-N\n",
    "pos_word_freq = pos_sum.sort_values(ascending=False).head(n)\n",
    "neg_word_freq = neg_sum.sort_values(ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c389c-1b4f-44a8-a5f6-c73f99df600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Positive words\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=pos_word_freq.values, y=pos_word_freq.index, hue=pos_word_freq.values)\n",
    "plt.title(\"Top Positive Words by TF-IDF\")\n",
    "plt.xlabel(\"TF-IDF Weight\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ae59a-216d-4674-be64-5137e4583136",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pos_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901329c-08fb-4c2f-b093-5dfe782d09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Negative words\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=neg_word_freq.values, y=neg_word_freq.index, hue=neg_word_freq.values)\n",
    "plt.title(\"Top Negative Words by TF-IDF\")\n",
    "plt.xlabel(\"TF-IDF Weight\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1607e6-e6e1-4654-935f-680aa3bfeb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "del neg_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047d87b-d144-43d5-a0c0-2ec0deb77695",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48afbd3-6b4f-451e-b024-044287cb7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/preped/preped_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696162f-e50b-482e-add3-300360613215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = [sentence.split() for sentence in df['processed_review']]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eab85-f634-4ec7-bf7d-45daec4b18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences=sentences, vector_size=500, window=12, min_count=5, sg=1, epochs=20, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af2a26-07ef-4f4a-b0bd-31ed0eae4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save('models/w2v/word2vac_vector_size=500_window=12_min_count=5_sg=1_epochs=20_workers=4.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57275d79-f568-435a-82f4-25b4d30d3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar('smart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a68695-e220-4152-9a61-d39bd83cfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402b448-af22-42dc-8fcf-13e09e78316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(positive=[\"king\", \"female\"], negative=[\"male\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdac184-9eaa-4f8f-8b8a-1f096dce05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.similarity(\"king\", \"female\"), w2v.wv.similarity(\"queen\", \"female\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220561b-a31e-4ec4-9f8d-c40ee82dfac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = w2v.wv['king'] - w2v.wv['male'] + w2v.wv['female']\n",
    "w2v.wv.similar_by_vector(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba34a1a-68c7-40d3-9e7e-c4af5f56e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "pad_vec = rng.normal(scale=0, size=w2v.vector_size).astype(np.float32)\n",
    "oov_vec = rng.normal(scale=0.01, size=w2v.vector_size).astype(np.float32)\n",
    "\n",
    "np.save('embeddings/pad_vec.npy', pad_vec)\n",
    "np.save('embeddings/oov_vec.npy', oov_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22dc34-f3cc-4219-94b4-20cc8cd2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_padded_embeddings(sentence, max_words):\n",
    "    model = w2v\n",
    "    embedding_dim = model.vector_size\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in sentence:\n",
    "        # in vocab\n",
    "        if word in model.wv:\n",
    "            embeddings.append(model.wv[word])\n",
    "        # out of vocab\n",
    "        else:\n",
    "            embeddings.append(oov_vec)\n",
    "\n",
    "    # tuncate\n",
    "    if len(embeddings) > max_words:\n",
    "        embeddings = embeddings[:max_words]\n",
    "    # paddinf\n",
    "    else:\n",
    "        while len(embeddings) < max_words:\n",
    "            embeddings.append(pad_vec)\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc73041-3cb2-4c6f-a1c5-569568def3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = get_w2v_padded_embeddings('absolutly hate coding'.split(), max_words=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c4d0e-ac89-40b7-8647-9b9f0c8c01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(a[2], oov_vec), np.array_equal(a[3], pad_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ecf54-d45f-400b-a616-d0f962593b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w2v_padded_embeddings(sentences[0], max_words=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976d11f-d1c2-4867-8a2d-007639039f20",
   "metadata": {},
   "source": [
    "## FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c19ba-8b9d-4381-9fbb-1e264cf1d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText(sentences=sentences, vector_size=500, window=12, min_count=5, sg=1, epochs=20, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a854c3a-735c-4f5b-a38a-0fbb7a75768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save('models/FastText/FastText_vector_size=500_window=12_min_count=5_sg=1_epochs=20_workers=4.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fd074-46c5-42d4-a328-16ca50b4b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.wv.most_similar('smart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb45bd-c912-496e-8730-6913b760db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3f684-af0b-4020-9960-fa5c76dffc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.wv.most_similar('bitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08049009-0894-4424-87c4-6ea94fa04f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.wv.most_similar(positive=[\"king\", \"female\"], negative=[\"male\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3113050-8823-42aa-8e7b-aff77af2b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ft.wv['king'] - ft.wv['male'] + ft.wv['female']\n",
    "ft.wv.similar_by_vector(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579886a6-6381-438a-9891-21b1a61e5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft_padded_embeddings(sentence, max_words):\n",
    "    model = ft\n",
    "    embedding_dim = model.vector_size\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in sentence:\n",
    "        embeddings.append(model.wv[word])\n",
    "\n",
    "    # tuncate\n",
    "    if len(embeddings) > max_words:\n",
    "        embeddings = embeddings[:max_words]\n",
    "    # paddinf\n",
    "    else:\n",
    "        while len(embeddings) < max_words:\n",
    "            embeddings.append(pad_vec)\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a939c-5fe4-4bfd-971a-ea511a58ef40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = get_ft_padded_embeddings('absolutly hate coding'.split(), max_words=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3748630-7b09-43f7-b64a-2a4010a2077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ft_padded_embeddings(sentences[0], max_words=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27ddd9-0b38-4b5d-9cf8-d611c25ec0fd",
   "metadata": {},
   "source": [
    "## BERT Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679822f-1301-4b6f-bbd0-6653cf617f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fd0e9-dcf5-457b-af4d-4800d0b31373",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5cd57-dca5-4d9c-bbe4-41b016090e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(['think', 'wonderful', 'way', 'spend', 'time', 'hot', 'summer', 'weekend', 'sit', 'air', 'condition', 'theater', 'watch', 'light', 'hearted', 'comedy', 'plot',\n",
    " 'simplistic', 'dialogue', 'witty', 'character', 'liable', 'bread', 'suspect', 'serial', 'killer', 'disappoint', 'realize', 'match', 'point', '2', 'risk', 'addiction', 'think',\n",
    " 'proof', 'woody', 'allen', 'fully', 'control', 'style', 'grow', 'love', 'this', 'laugh', 'woody', 'comedy', 'year', 'dare', 'decade', 'impress', 'scarlet', 'johnson', 'manage',\n",
    " 'tone', 'sexy', 'image', 'jump', 'right', 'average', 'spirited', 'young', 'woman', 'this', 'crown', 'jewel', 'career', 'winter', 'devil', 'wear', 'prada', 'interesting', 'superman',\n",
    " 'great', 'comedy', 'friend'])\n",
    "\n",
    "encoded_input = tokenizer.batch_encode_plus( [text],# List of input texts\n",
    "    padding=True,              # Pad to the maximum sequence length\n",
    "    truncation=True,           # Truncate to the maximum sequence length if necessary\n",
    "    return_tensors='pt',      # Return PyTorch tensors\n",
    "    add_special_tokens=True    # Add special tokens CLS and SEP\n",
    ")\n",
    "\n",
    "input_ids = encoded_input['input_ids']  # Token IDs\n",
    "# print input IDs\n",
    "print(f\"Input ID: {input_ids}\")\n",
    "attention_mask = encoded_input['attention_mask']  # Attention mask\n",
    "# print attention mask\n",
    "print(f\"Attention mask: {attention_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4acc0e-ebb0-4a25-8af7-4b7f842ba657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "outputs = model(**encoded_input)\n",
    "# The embeddings are in the `last_hidden_state` attribute of the outputs\n",
    "token_embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b54d1-c23c-4061-bf9b-bb02d610b769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sentiment_analysis)",
   "language": "python",
   "name": "sentiment_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
