{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eb4cb4-da04-49e2-99c3-29e4e9adcbc2",
   "metadata": {},
   "source": [
    "# Sentiment Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfda9d-70f8-4b3c-a61e-3bf296da35dd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97a4ccf-38b8-435a-a730-e84bc774182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import (\n",
    "    MultinomialNB, ComplementNB, GaussianNB\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.feature_engineering import *\n",
    "from src.utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81b053-9723-4619-b4b7-e502d55e947c",
   "metadata": {},
   "source": [
    "## Loading Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187de2f-75c5-4c81-a4ef-804e21cf699a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30266c44-74cf-4b1a-afce-39e705f64d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265fd198-aeef-4a53-8990-e1fef63f9679",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4099e42-73fc-4fc1-852a-79cd6a999cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_charecters_len</th>\n",
       "      <th>review_word_len</th>\n",
       "      <th>has_html</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_review_charecter_len</th>\n",
       "      <th>cleaned_review_word_len</th>\n",
       "      <th>cleaned_review_has_html</th>\n",
       "      <th>positive_tokens</th>\n",
       "      <th>negative_tokens</th>\n",
       "      <th>positive_tokens_len</th>\n",
       "      <th>negative_tokens_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1377</td>\n",
       "      <td>320</td>\n",
       "      <td>True</td>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "      <td>931</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>[right, right, trust, regard, classic, appeal,...</td>\n",
       "      <td>[struck, brutality, faint, timid, punch, priso...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>793</td>\n",
       "      <td>166</td>\n",
       "      <td>True</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>557</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>[wonderful, comforting, well, seamless, well, ...</td>\n",
       "      <td>[terribly]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>172</td>\n",
       "      <td>True</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>495</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "      <td>[wonderful, hot, witty, likable, well, impress...</td>\n",
       "      <td>[plot, simplistic, killer, disappointed, risk,...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
       "      <td>362</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>[like, well]</td>\n",
       "      <td>[zombie, slower, kill, ruin, meaningless, ignore]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>1032</td>\n",
       "      <td>236</td>\n",
       "      <td>True</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>725</td>\n",
       "      <td>123</td>\n",
       "      <td>False</td>\n",
       "      <td>[love, stunning, vivid, success, stylishly, so...</td>\n",
       "      <td>[loneliness, anxiously]</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "\n",
       "   review_charecters_len  review_word_len  has_html  \\\n",
       "0                   1377              320      True   \n",
       "1                    793              166      True   \n",
       "2                    721              172      True   \n",
       "3                    569              141      True   \n",
       "4                   1032              236      True   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one reviewer mentioned watching oz episode hoo...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically family little boy jake think zombie ...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [one, reviewer, mentioned, watching, oz, episo...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, family, little, boy, jake, think, ...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "   cleaned_review_charecter_len  cleaned_review_word_len  \\\n",
       "0                           931                      162   \n",
       "1                           557                       84   \n",
       "2                           495                       83   \n",
       "3                           362                       62   \n",
       "4                           725                      123   \n",
       "\n",
       "   cleaned_review_has_html                                    positive_tokens  \\\n",
       "0                    False  [right, right, trust, regard, classic, appeal,...   \n",
       "1                    False  [wonderful, comforting, well, seamless, well, ...   \n",
       "2                    False  [wonderful, hot, witty, likable, well, impress...   \n",
       "3                    False                                       [like, well]   \n",
       "4                    False  [love, stunning, vivid, success, stylishly, so...   \n",
       "\n",
       "                                     negative_tokens  positive_tokens_len  \\\n",
       "0  [struck, brutality, faint, timid, punch, priso...                   13   \n",
       "1                                         [terribly]                   11   \n",
       "2  [plot, simplistic, killer, disappointed, risk,...                   11   \n",
       "3  [zombie, slower, kill, ruin, meaningless, ignore]                    2   \n",
       "4                            [loneliness, anxiously]                   15   \n",
       "\n",
       "   negative_tokens_len  \n",
       "0                   20  \n",
       "1                    1  \n",
       "2                    6  \n",
       "3                    6  \n",
       "4                    2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_pickle(\"../data/interim/IMDB_feature_engineered.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3ff0e4-ffef-48fa-8005-8fba67385c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"review_charecters_len\",\"review_word_len\",\n",
    "features = [\"cleaned_review_charecter_len\",\"cleaned_review_word_len\",\"positive_tokens_len\",\"negative_tokens_len\"]\n",
    "target = \"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc6ef74-d619-4bc6-99b8-f8754c2c0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorized = load_npz(\"../data/interim/count_vectorized_reviwes.npz\")\n",
    "tfidfVectorized = load_npz(\"../data/interim/tfidf_vectorized_reviwes.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9a5a89-64cd-4be4-ad71-98338b1e960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       " \twith 5044360 stored elements and shape (50000, 20000)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       " \twith 5044360 stored elements and shape (50000, 20000)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVectorized, tfidfVectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074711e2-90b2-4879-9e58-0161435e8566",
   "metadata": {},
   "source": [
    "## SSplitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe7b507-c44a-44a0-b69a-1a6d848af9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36dd8bc1-7da6-4fe5-8f0b-1d30e1243d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[features] \n",
    "y = df[target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0cea1c-992c-49ea-be2f-aef73ce90c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_X, y, test_size=test_size, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be84033d-45ef-47a9-b5b3-94dc449364d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 4), (10000, 4), (40000,), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.shape, df_X_test.shape, df_y_train.shape, df_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd554ec-a115-43a7-86b2-69a133f8da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_X_train, count_X_test, count_y_train, count_y_test = train_test_split(countVectorized, y, test_size=test_size, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe93894-3226-4d49-b66a-767d050f026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 20000), (10000, 20000), (40000,), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_X_train.shape, count_X_test.shape, count_y_train.shape, count_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6867debd-ab9a-4069-92ba-23b037471a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_train, tfidf_X_test, tfidf_y_train, tfidf_y_test = train_test_split(tfidfVectorized, y, test_size=test_size, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19715827-68d9-48e4-abf6-0e6a76c900c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 20000), (10000, 20000), (40000,), (10000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X_train.shape, tfidf_X_test.shape, tfidf_y_train.shape, tfidf_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a0f2551-4e0d-4763-aff2-2f37c77e05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e58bb4-0cc3-4f5f-8e67-e2ae439794a1",
   "metadata": {},
   "source": [
    "## Traning models on Numeric cols in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7483d0d-c7f8-4d8e-b581-7b8113405bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000), \n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e3155ef-895f-48ec-9ef8-49ea7373754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "Training LinearSVC...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training RandomForestClassifier...\n",
      "Training ExtraTreesClassifier...\n",
      "\n",
      "Evaluation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.729125</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>0.735506</td>\n",
       "      <td>0.795237</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.724727</td>\n",
       "      <td>0.7556</td>\n",
       "      <td>0.739841</td>\n",
       "      <td>0.797317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.729125</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>0.735506</td>\n",
       "      <td>0.795237</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.724727</td>\n",
       "      <td>0.7556</td>\n",
       "      <td>0.739841</td>\n",
       "      <td>0.797317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.732125</td>\n",
       "      <td>0.731189</td>\n",
       "      <td>0.73415</td>\n",
       "      <td>0.732666</td>\n",
       "      <td>0.797839</td>\n",
       "      <td>0.7357</td>\n",
       "      <td>0.737075</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.799777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.732050</td>\n",
       "      <td>0.731287</td>\n",
       "      <td>0.73370</td>\n",
       "      <td>0.732491</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.736779</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.734784</td>\n",
       "      <td>0.799848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.99595</td>\n",
       "      <td>0.995676</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.711708</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.702845</td>\n",
       "      <td>0.771588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.995725</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.99165</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.692339</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.684072</td>\n",
       "      <td>0.751558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train_Accuracy  Train_Precision  Train_Recall  \\\n",
       "3            ComplementNB        0.729125         0.718579       0.75325   \n",
       "2           MultinomialNB        0.729125         0.718579       0.75325   \n",
       "1               LinearSVC        0.732125         0.731189       0.73415   \n",
       "0      LogisticRegression        0.732050         0.731287       0.73370   \n",
       "4  RandomForestClassifier        0.995675         0.995403       0.99595   \n",
       "5    ExtraTreesClassifier        0.995725         0.999798       0.99165   \n",
       "\n",
       "   Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  Test_Recall  \\\n",
       "3        0.735506       0.795237         0.7343        0.724727       0.7556   \n",
       "2        0.735506       0.795237         0.7343        0.724727       0.7556   \n",
       "1        0.732666       0.797839         0.7357        0.737075       0.7328   \n",
       "0        0.732491       0.797900         0.7355        0.736779       0.7328   \n",
       "4        0.995676       0.999930         0.7065        0.711708       0.6942   \n",
       "5        0.995708       0.999963         0.6878        0.692339       0.6760   \n",
       "\n",
       "   Test_F1-Score  Test_ROC-AUC  \n",
       "3       0.739841      0.797317  \n",
       "2       0.739841      0.797317  \n",
       "1       0.734931      0.799777  \n",
       "0       0.734784      0.799848  \n",
       "4       0.702845      0.771588  \n",
       "5       0.684072      0.751558  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in df_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    model.fit(df_X_train, df_y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(df_X_train)\n",
    "    y_test_pred = model.predict(df_X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(df_X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(df_X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_train_proba = model.decision_function(df_X_train)\n",
    "        y_test_proba = model.decision_function(df_X_test)\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    model_result = {\"Model\": name}\n",
    "\n",
    "    for dataset_type, y_true, y_pred, y_proba in [\n",
    "        ('Train', df_y_train, y_train_pred, y_train_proba),\n",
    "        ('Test', df_y_test, y_test_pred, y_test_proba)\n",
    "    ]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_proba) if y_proba is not None else np.nan\n",
    "        \n",
    "        model_result[dataset_type + \"_\" + \"Accuracy\"] = accuracy\n",
    "        model_result[dataset_type + \"_\" + \"Precision\"] = precision\n",
    "        model_result[dataset_type + \"_\" + \"Recall\"] = recall\n",
    "        model_result[dataset_type + \"_\" + \"F1-Score\"] = f1\n",
    "        model_result[dataset_type + \"_\" + \"ROC-AUC\"] = roc_auc\n",
    "        \n",
    "    results.append(model_result)\n",
    "\n",
    "print(\"\\nEvaluation Complete.\")\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(df_results, \"../results/metrics/df_results.csv\")\n",
    "save_pickle(df_models, \"../models/df_models.pkl\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44ceb0e4-ac10-474f-b1bb-75f494bf466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000), \n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b327d009-3cf2-40cc-bf6c-a452035d96e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-Fold CV for LogisticRegression...\n",
      "Running 5-Fold CV for LinearSVC...\n",
      "Running 5-Fold CV for MultinomialNB...\n",
      "Running 5-Fold CV for ComplementNB...\n",
      "Running 5-Fold CV for RandomForestClassifier...\n",
      "Running 5-Fold CV for ExtraTreesClassifier...\n",
      "\n",
      "Cross-Validation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fit_Time_sec</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>0.730098</td>\n",
       "      <td>0.719887</td>\n",
       "      <td>0.753316</td>\n",
       "      <td>0.736222</td>\n",
       "      <td>0.795684</td>\n",
       "      <td>0.73002</td>\n",
       "      <td>0.719767</td>\n",
       "      <td>0.75336</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.795656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.730098</td>\n",
       "      <td>0.719887</td>\n",
       "      <td>0.753316</td>\n",
       "      <td>0.736222</td>\n",
       "      <td>0.795684</td>\n",
       "      <td>0.73002</td>\n",
       "      <td>0.719767</td>\n",
       "      <td>0.75336</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.795656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.532806</td>\n",
       "      <td>0.732591</td>\n",
       "      <td>0.732472</td>\n",
       "      <td>0.732849</td>\n",
       "      <td>0.732660</td>\n",
       "      <td>0.798258</td>\n",
       "      <td>0.73272</td>\n",
       "      <td>0.732596</td>\n",
       "      <td>0.73300</td>\n",
       "      <td>0.732784</td>\n",
       "      <td>0.798209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.732468</td>\n",
       "      <td>0.732116</td>\n",
       "      <td>0.732291</td>\n",
       "      <td>0.798171</td>\n",
       "      <td>0.73258</td>\n",
       "      <td>0.732651</td>\n",
       "      <td>0.73244</td>\n",
       "      <td>0.732530</td>\n",
       "      <td>0.798123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>17.891951</td>\n",
       "      <td>0.995296</td>\n",
       "      <td>0.995452</td>\n",
       "      <td>0.995138</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.69966</td>\n",
       "      <td>0.705607</td>\n",
       "      <td>0.68524</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.767708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>12.964830</td>\n",
       "      <td>0.995358</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.995337</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.68610</td>\n",
       "      <td>0.690795</td>\n",
       "      <td>0.67384</td>\n",
       "      <td>0.682178</td>\n",
       "      <td>0.747613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Fit_Time_sec  Train_Accuracy  Train_Precision  \\\n",
       "3            ComplementNB      0.037047        0.730098         0.719887   \n",
       "2           MultinomialNB      0.041717        0.730098         0.719887   \n",
       "0      LogisticRegression      0.532806        0.732591         0.732472   \n",
       "1               LinearSVC      0.259542        0.732356         0.732468   \n",
       "4  RandomForestClassifier     17.891951        0.995296         0.995452   \n",
       "5    ExtraTreesClassifier     12.964830        0.995358         0.999807   \n",
       "\n",
       "   Train_Recall  Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  \\\n",
       "3      0.753316        0.736222       0.795684        0.73002        0.719767   \n",
       "2      0.753316        0.736222       0.795684        0.73002        0.719767   \n",
       "0      0.732849        0.732660       0.798258        0.73272        0.732596   \n",
       "1      0.732116        0.732291       0.798171        0.73258        0.732651   \n",
       "4      0.995138        0.995295       0.999922        0.69966        0.705607   \n",
       "5      0.990907        0.995337       0.999957        0.68610        0.690795   \n",
       "\n",
       "   Test_Recall  Test_F1-Score  Test_ROC-AUC  \n",
       "3      0.75336       0.736172      0.795656  \n",
       "2      0.75336       0.736172      0.795656  \n",
       "0      0.73300       0.732784      0.798209  \n",
       "1      0.73244       0.732530      0.798123  \n",
       "4      0.68524       0.695261      0.767708  \n",
       "5      0.67384       0.682178      0.747613  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_metrics = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'roc_auc'\n",
    "]\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "\n",
    "for name, model in df_cv_models.items():\n",
    "    print(f\"Running {folds}-Fold CV for {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_validate(\n",
    "        estimator=model,\n",
    "        X=df_X, # Use ALL data for CV\n",
    "        y=y,\n",
    "        cv=cv_strategy, # 5 folds\n",
    "        scoring=scoring_metrics,\n",
    "        return_train_score=True, # Get train scores for overfitting check\n",
    "        n_jobs=-1 # Use all cores for parallel processing\n",
    "    )\n",
    "    \n",
    "    # Store the average results\n",
    "    model_data = {\n",
    "        \"Model\": name,\n",
    "        \"Fit_Time_sec\": np.mean(scores['fit_time']),\n",
    "        \"Train_Accuracy\": np.mean(scores['train_accuracy']),\n",
    "        \"Train_Precision\": np.mean(scores['train_precision']),\n",
    "        \"Train_Recall\": np.mean(scores['train_recall']),\n",
    "        \"Train_F1-Score\": np.mean(scores['train_f1']),\n",
    "        \"Train_ROC-AUC\": np.mean(scores['train_roc_auc']),\n",
    "        \"Test_Accuracy\": np.mean(scores['test_accuracy']),\n",
    "        \"Test_Precision\": np.mean(scores['test_precision']),\n",
    "        \"Test_Recall\": np.mean(scores['test_recall']),\n",
    "        \"Test_F1-Score\": np.mean(scores['test_f1']),\n",
    "        \"Test_ROC-AUC\": np.mean(scores['test_roc_auc']),\n",
    "    }\n",
    "    cv_results.append(model_data)\n",
    "\n",
    "df_cv_results = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Complete.\")\n",
    "df_cv_results = df_cv_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(df_cv_results, \"../results/metrics/df_cv_results.csv\")\n",
    "save_pickle(df_cv_models, \"../models/df_cv_models.pkl\")\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fea0f-f885-45ff-b263-f1168d07cf3d",
   "metadata": {},
   "source": [
    "## Traning models on count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de2c7c1-1c95-47f4-bf53-ce46807a637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_models = {\n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000),  \n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "039684db-a975-4249-9e4d-e85807c6e35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearSVC...\n",
      "Training LogisticRegression...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training RandomForestClassifier...\n",
      "Training ExtraTreesClassifier...\n",
      "\n",
      "Evaluation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.996752</td>\n",
       "      <td>0.99745</td>\n",
       "      <td>0.997101</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>0.878559</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.880575</td>\n",
       "      <td>0.947454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.875300</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.875650</td>\n",
       "      <td>0.945764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.879483</td>\n",
       "      <td>0.88410</td>\n",
       "      <td>0.881785</td>\n",
       "      <td>0.943762</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.865586</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.870663</td>\n",
       "      <td>0.932010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.879483</td>\n",
       "      <td>0.88410</td>\n",
       "      <td>0.881785</td>\n",
       "      <td>0.943761</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.865586</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.870663</td>\n",
       "      <td>0.932028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8626</td>\n",
       "      <td>0.862890</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.862545</td>\n",
       "      <td>0.931830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.857482</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.862511</td>\n",
       "      <td>0.932952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train_Accuracy  Train_Precision  Train_Recall  \\\n",
       "1      LogisticRegression        0.997100         0.996752       0.99745   \n",
       "5    ExtraTreesClassifier        1.000000         1.000000       1.00000   \n",
       "3            ComplementNB        0.881475         0.879483       0.88410   \n",
       "2           MultinomialNB        0.881475         0.879483       0.88410   \n",
       "0               LinearSVC        1.000000         1.000000       1.00000   \n",
       "4  RandomForestClassifier        1.000000         1.000000       1.00000   \n",
       "\n",
       "   Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  Test_Recall  \\\n",
       "1        0.997101       0.999929         0.8803        0.878559       0.8826   \n",
       "5        1.000000       1.000000         0.8756        0.875300       0.8760   \n",
       "3        0.881785       0.943762         0.8699        0.865586       0.8758   \n",
       "2        0.881785       0.943761         0.8699        0.865586       0.8758   \n",
       "0        1.000000       1.000000         0.8626        0.862890       0.8622   \n",
       "4        1.000000       1.000000         0.8617        0.857482       0.8676   \n",
       "\n",
       "   Test_F1-Score  Test_ROC-AUC  \n",
       "1       0.880575      0.947454  \n",
       "5       0.875650      0.945764  \n",
       "3       0.870663      0.932010  \n",
       "2       0.870663      0.932028  \n",
       "0       0.862545      0.931830  \n",
       "4       0.862511      0.932952  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in count_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    model.fit(count_X_train, count_y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(count_X_train)\n",
    "    y_test_pred = model.predict(count_X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(count_X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(count_X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_train_proba = model.decision_function(count_X_train)\n",
    "        y_test_proba = model.decision_function(count_X_test)\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    model_result = {\"Model\": name}\n",
    "\n",
    "    for dataset_type, y_true, y_pred, y_proba in [\n",
    "        ('Train', count_y_train, y_train_pred, y_train_proba),\n",
    "        ('Test', count_y_test, y_test_pred, y_test_proba)\n",
    "    ]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_proba) if y_proba is not None else np.nan\n",
    "        \n",
    "        model_result[dataset_type + \"_\" + \"Accuracy\"] = accuracy\n",
    "        model_result[dataset_type + \"_\" + \"Precision\"] = precision\n",
    "        model_result[dataset_type + \"_\" + \"Recall\"] = recall\n",
    "        model_result[dataset_type + \"_\" + \"F1-Score\"] = f1\n",
    "        model_result[dataset_type + \"_\" + \"ROC-AUC\"] = roc_auc\n",
    "        \n",
    "    results.append(model_result)\n",
    "\n",
    "print(\"\\nEvaluation Complete.\")\n",
    "count_results = pd.DataFrame(results)\n",
    "count_results = count_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(count_results, \"../results/metrics/count_results.csv\")\n",
    "save_pickle(count_models, \"../models/count_models.pkl\")\n",
    "count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f7cac40-e57b-4b6b-ad7f-082c6dc85b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cv_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000), \n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba7a09bd-97ec-424e-8be5-0cc65cac535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-Fold CV for LogisticRegression...\n",
      "Running 5-Fold CV for LinearSVC...\n",
      "Running 5-Fold CV for MultinomialNB...\n",
      "Running 5-Fold CV for ComplementNB...\n",
      "Running 5-Fold CV for RandomForestClassifier...\n",
      "Running 5-Fold CV for ExtraTreesClassifier...\n",
      "\n",
      "Cross-Validation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fit_Time_sec</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>17.192942</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.996627</td>\n",
       "      <td>0.996073</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.88134</td>\n",
       "      <td>0.878941</td>\n",
       "      <td>0.88460</td>\n",
       "      <td>0.881722</td>\n",
       "      <td>0.946948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>651.651123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.87492</td>\n",
       "      <td>0.876682</td>\n",
       "      <td>0.87260</td>\n",
       "      <td>0.874625</td>\n",
       "      <td>0.943940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.263666</td>\n",
       "      <td>0.880358</td>\n",
       "      <td>0.877934</td>\n",
       "      <td>0.883564</td>\n",
       "      <td>0.880740</td>\n",
       "      <td>0.942488</td>\n",
       "      <td>0.86554</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.86980</td>\n",
       "      <td>0.866087</td>\n",
       "      <td>0.929630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.247663</td>\n",
       "      <td>0.880358</td>\n",
       "      <td>0.877934</td>\n",
       "      <td>0.883564</td>\n",
       "      <td>0.880740</td>\n",
       "      <td>0.942489</td>\n",
       "      <td>0.86554</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.86980</td>\n",
       "      <td>0.866087</td>\n",
       "      <td>0.929630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>198.415673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.86008</td>\n",
       "      <td>0.859869</td>\n",
       "      <td>0.86044</td>\n",
       "      <td>0.860115</td>\n",
       "      <td>0.929780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>477.518050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.85600</td>\n",
       "      <td>0.854219</td>\n",
       "      <td>0.85856</td>\n",
       "      <td>0.856368</td>\n",
       "      <td>0.931241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Fit_Time_sec  Train_Accuracy  Train_Precision  \\\n",
       "0      LogisticRegression     17.192942        0.996071         0.995521   \n",
       "5    ExtraTreesClassifier    651.651123        1.000000         1.000000   \n",
       "3            ComplementNB      0.263666        0.880358         0.877934   \n",
       "2           MultinomialNB      0.247663        0.880358         0.877934   \n",
       "1               LinearSVC    198.415673        1.000000         1.000000   \n",
       "4  RandomForestClassifier    477.518050        1.000000         1.000000   \n",
       "\n",
       "   Train_Recall  Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  \\\n",
       "0      0.996627        0.996073       0.999864        0.88134        0.878941   \n",
       "5      1.000000        1.000000       1.000000        0.87492        0.876682   \n",
       "3      0.883564        0.880740       0.942488        0.86554        0.862454   \n",
       "2      0.883564        0.880740       0.942489        0.86554        0.862454   \n",
       "1      1.000000        1.000000       1.000000        0.86008        0.859869   \n",
       "4      1.000000        1.000000       1.000000        0.85600        0.854219   \n",
       "\n",
       "   Test_Recall  Test_F1-Score  Test_ROC-AUC  \n",
       "0      0.88460       0.881722      0.946948  \n",
       "5      0.87260       0.874625      0.943940  \n",
       "3      0.86980       0.866087      0.929630  \n",
       "2      0.86980       0.866087      0.929630  \n",
       "1      0.86044       0.860115      0.929780  \n",
       "4      0.85856       0.856368      0.931241  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_metrics = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'roc_auc'\n",
    "]\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "\n",
    "for name, model in count_cv_models.items():\n",
    "    print(f\"Running {folds}-Fold CV for {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_validate(\n",
    "        estimator=model,\n",
    "        X=countVectorized, # Use ALL data for CV\n",
    "        y=y,\n",
    "        cv=cv_strategy, # 5 folds\n",
    "        scoring=scoring_metrics,\n",
    "        return_train_score=True, # Get train scores for overfitting check\n",
    "        n_jobs=-1 # Use all cores for parallel processing\n",
    "    )\n",
    "    \n",
    "    # Store the average results\n",
    "    model_data = {\n",
    "        \"Model\": name,\n",
    "        \"Fit_Time_sec\": np.mean(scores['fit_time']),\n",
    "        \"Train_Accuracy\": np.mean(scores['train_accuracy']),\n",
    "        \"Train_Precision\": np.mean(scores['train_precision']),\n",
    "        \"Train_Recall\": np.mean(scores['train_recall']),\n",
    "        \"Train_F1-Score\": np.mean(scores['train_f1']),\n",
    "        \"Train_ROC-AUC\": np.mean(scores['train_roc_auc']),\n",
    "        \"Test_Accuracy\": np.mean(scores['test_accuracy']),\n",
    "        \"Test_Precision\": np.mean(scores['test_precision']),\n",
    "        \"Test_Recall\": np.mean(scores['test_recall']),\n",
    "        \"Test_F1-Score\": np.mean(scores['test_f1']),\n",
    "        \"Test_ROC-AUC\": np.mean(scores['test_roc_auc']),\n",
    "    }\n",
    "    cv_results.append(model_data)\n",
    "\n",
    "count_cv_results = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Complete.\")\n",
    "count_cv_results = count_cv_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(count_cv_results, \"../results/metrics/count_cv_results.csv\")\n",
    "save_pickle(count_cv_models, \"../models/count_cv_models.pkl\")\n",
    "count_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79981861-e623-4397-bcc3-92fd2fb86117",
   "metadata": {},
   "source": [
    "# Traning models on count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdc4289-766d-4041-909c-6c53a835592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000), \n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65fa8e1e-e705-43c1-9e8b-4291e2af9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "Training LinearSVC...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training RandomForestClassifier...\n",
      "Training ExtraTreesClassifier...\n",
      "\n",
      "Evaluation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.927450</td>\n",
       "      <td>0.919521</td>\n",
       "      <td>0.93690</td>\n",
       "      <td>0.928129</td>\n",
       "      <td>0.979258</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.894964</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.904088</td>\n",
       "      <td>0.964590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.979825</td>\n",
       "      <td>0.98345</td>\n",
       "      <td>0.981634</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.891450</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.961497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.894175</td>\n",
       "      <td>0.885181</td>\n",
       "      <td>0.90585</td>\n",
       "      <td>0.895396</td>\n",
       "      <td>0.959201</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>0.862556</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.877224</td>\n",
       "      <td>0.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.894175</td>\n",
       "      <td>0.885181</td>\n",
       "      <td>0.90585</td>\n",
       "      <td>0.895396</td>\n",
       "      <td>0.959201</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>0.862556</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.877224</td>\n",
       "      <td>0.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.874253</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.944765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.861686</td>\n",
       "      <td>0.936078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train_Accuracy  Train_Precision  Train_Recall  \\\n",
       "0      LogisticRegression        0.927450         0.919521       0.93690   \n",
       "1               LinearSVC        0.981600         0.979825       0.98345   \n",
       "2           MultinomialNB        0.894175         0.885181       0.90585   \n",
       "3            ComplementNB        0.894175         0.885181       0.90585   \n",
       "5    ExtraTreesClassifier        1.000000         1.000000       1.00000   \n",
       "4  RandomForestClassifier        1.000000         1.000000       1.00000   \n",
       "\n",
       "   Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  Test_Recall  \\\n",
       "0        0.928129       0.979258         0.9031        0.894964       0.9134   \n",
       "1        0.981634       0.998145         0.8974        0.891450       0.9050   \n",
       "2        0.895396       0.959201         0.8751        0.862556       0.8924   \n",
       "3        0.895396       0.959201         0.8751        0.862556       0.8924   \n",
       "5        1.000000       1.000000         0.8756        0.874253       0.8774   \n",
       "4        1.000000       1.000000         0.8617        0.861772       0.8616   \n",
       "\n",
       "   Test_F1-Score  Test_ROC-AUC  \n",
       "0       0.904088      0.964590  \n",
       "1       0.898174      0.961497  \n",
       "2       0.877224      0.946800  \n",
       "3       0.877224      0.946800  \n",
       "5       0.875824      0.944765  \n",
       "4       0.861686      0.936078  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in tfidf_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    model.fit(tfidf_X_train, tfidf_y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(tfidf_X_train)\n",
    "    y_test_pred = model.predict(tfidf_X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(tfidf_X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(tfidf_X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_train_proba = model.decision_function(tfidf_X_train)\n",
    "        y_test_proba = model.decision_function(tfidf_X_test)\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    model_result = {\"Model\": name}\n",
    "\n",
    "    for dataset_type, y_true, y_pred, y_proba in [\n",
    "        ('Train', tfidf_y_train, y_train_pred, y_train_proba),\n",
    "        ('Test', tfidf_y_test, y_test_pred, y_test_proba)\n",
    "    ]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_proba) if y_proba is not None else np.nan\n",
    "        \n",
    "        model_result[dataset_type + \"_\" + \"Accuracy\"] = accuracy\n",
    "        model_result[dataset_type + \"_\" + \"Precision\"] = precision\n",
    "        model_result[dataset_type + \"_\" + \"Recall\"] = recall\n",
    "        model_result[dataset_type + \"_\" + \"F1-Score\"] = f1\n",
    "        model_result[dataset_type + \"_\" + \"ROC-AUC\"] = roc_auc\n",
    "        \n",
    "    results.append(model_result)\n",
    "\n",
    "print(\"\\nEvaluation Complete.\")\n",
    "tfidf_results = pd.DataFrame(results)\n",
    "tfidf_results = tfidf_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(tfidf_results, \"../results/metrics/tfidf_results.csv\")\n",
    "save_pickle(tfidf_models, \"../models/tfidf_models.pkl\")\n",
    "tfidf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b73ce7ed-73d3-4b71-a74e-c87da6769abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cv_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=1000), \n",
    "    \"LinearSVC\": LinearSVC(random_state=42, max_iter=5000), \n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41e7e9fa-cccf-4a03-a1a3-b802064559de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-Fold CV for LogisticRegression...\n",
      "Running 5-Fold CV for LinearSVC...\n",
      "Running 5-Fold CV for MultinomialNB...\n",
      "Running 5-Fold CV for ComplementNB...\n",
      "Running 5-Fold CV for RandomForestClassifier...\n",
      "Running 5-Fold CV for ExtraTreesClassifier...\n",
      "\n",
      "Cross-Validation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fit_Time_sec</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1-Score</th>\n",
       "      <th>Train_ROC-AUC</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1-Score</th>\n",
       "      <th>Test_ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.917200</td>\n",
       "      <td>0.930924</td>\n",
       "      <td>0.924049</td>\n",
       "      <td>0.939031</td>\n",
       "      <td>0.931480</td>\n",
       "      <td>0.980964</td>\n",
       "      <td>0.89880</td>\n",
       "      <td>0.890782</td>\n",
       "      <td>0.90908</td>\n",
       "      <td>0.899826</td>\n",
       "      <td>0.962854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>5.855544</td>\n",
       "      <td>0.979162</td>\n",
       "      <td>0.976867</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.979212</td>\n",
       "      <td>0.997744</td>\n",
       "      <td>0.89308</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>0.89860</td>\n",
       "      <td>0.893658</td>\n",
       "      <td>0.959203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.262634</td>\n",
       "      <td>0.892602</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.905089</td>\n",
       "      <td>0.893927</td>\n",
       "      <td>0.958285</td>\n",
       "      <td>0.87484</td>\n",
       "      <td>0.864539</td>\n",
       "      <td>0.88900</td>\n",
       "      <td>0.876574</td>\n",
       "      <td>0.945481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.892602</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.905089</td>\n",
       "      <td>0.893927</td>\n",
       "      <td>0.958285</td>\n",
       "      <td>0.87484</td>\n",
       "      <td>0.864539</td>\n",
       "      <td>0.88900</td>\n",
       "      <td>0.876574</td>\n",
       "      <td>0.945481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>663.145445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.86846</td>\n",
       "      <td>0.867887</td>\n",
       "      <td>0.86928</td>\n",
       "      <td>0.868557</td>\n",
       "      <td>0.940811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>444.101484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.85560</td>\n",
       "      <td>0.855997</td>\n",
       "      <td>0.85508</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.932736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Fit_Time_sec  Train_Accuracy  Train_Precision  \\\n",
       "0      LogisticRegression      1.917200        0.930924         0.924049   \n",
       "1               LinearSVC      5.855544        0.979162         0.976867   \n",
       "2           MultinomialNB      0.262634        0.892602         0.883037   \n",
       "3            ComplementNB      0.241003        0.892602         0.883037   \n",
       "5    ExtraTreesClassifier    663.145445        1.000000         1.000000   \n",
       "4  RandomForestClassifier    444.101484        1.000000         1.000000   \n",
       "\n",
       "   Train_Recall  Train_F1-Score  Train_ROC-AUC  Test_Accuracy  Test_Precision  \\\n",
       "0      0.939031        0.931480       0.980964        0.89880        0.890782   \n",
       "1      0.981569        0.979212       0.997744        0.89308        0.888821   \n",
       "2      0.905089        0.893927       0.958285        0.87484        0.864539   \n",
       "3      0.905089        0.893927       0.958285        0.87484        0.864539   \n",
       "5      1.000000        1.000000       1.000000        0.86846        0.867887   \n",
       "4      1.000000        1.000000       1.000000        0.85560        0.855997   \n",
       "\n",
       "   Test_Recall  Test_F1-Score  Test_ROC-AUC  \n",
       "0      0.90908       0.899826      0.962854  \n",
       "1      0.89860       0.893658      0.959203  \n",
       "2      0.88900       0.876574      0.945481  \n",
       "3      0.88900       0.876574      0.945481  \n",
       "5      0.86928       0.868557      0.940811  \n",
       "4      0.85508       0.855525      0.932736  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_metrics = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'roc_auc'\n",
    "]\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "\n",
    "for name, model in tfidf_cv_models.items():\n",
    "    print(f\"Running {folds}-Fold CV for {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_validate(\n",
    "        estimator=model,\n",
    "        X=tfidfVectorized, # Use ALL data for CV\n",
    "        y=y,\n",
    "        cv=cv_strategy, # 5 folds\n",
    "        scoring=scoring_metrics,\n",
    "        return_train_score=True, # Get train scores for overfitting check\n",
    "        n_jobs=-1 # Use all cores for parallel processing\n",
    "    )\n",
    "    \n",
    "    # Store the average results\n",
    "    model_data = {\n",
    "        \"Model\": name,\n",
    "        \"Fit_Time_sec\": np.mean(scores['fit_time']),\n",
    "        \"Train_Accuracy\": np.mean(scores['train_accuracy']),\n",
    "        \"Train_Precision\": np.mean(scores['train_precision']),\n",
    "        \"Train_Recall\": np.mean(scores['train_recall']),\n",
    "        \"Train_F1-Score\": np.mean(scores['train_f1']),\n",
    "        \"Train_ROC-AUC\": np.mean(scores['train_roc_auc']),\n",
    "        \"Test_Accuracy\": np.mean(scores['test_accuracy']),\n",
    "        \"Test_Precision\": np.mean(scores['test_precision']),\n",
    "        \"Test_Recall\": np.mean(scores['test_recall']),\n",
    "        \"Test_F1-Score\": np.mean(scores['test_f1']),\n",
    "        \"Test_ROC-AUC\": np.mean(scores['test_roc_auc']),\n",
    "    }\n",
    "    cv_results.append(model_data)\n",
    "\n",
    "tfidf_cv_results = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Complete.\")\n",
    "tfidf_cv_results = tfidf_cv_results.sort_values(by='Test_F1-Score', ascending=False)\n",
    "save_data_csv(tfidf_cv_results, \"../results/metrics/tfidf_cv_results.csv\")\n",
    "save_pickle(tfidf_cv_models, \"../models/tfidf_cv_models.pkl\")\n",
    "tfidf_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e99e-dae8-4b02-a478-17e87340f0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
